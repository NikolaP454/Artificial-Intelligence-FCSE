{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Problem Text\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nДадено е податочно множество во променливата dataset. Последната колона ја претставува класата (0 или 1). Сите атрибути кои ги содржи се од нумерички тип.\\n\\nПотребно е да направите 4 модели на класификација:\\n\\n-  Наивен баесов класификатор.\\n-  Дрво на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.\\n-  Класификатор со колекција од 4 дрва на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.\\n-  Невронска мрежа со 10 неврони, ReLU активациска функција, 0.001 рата на учење.\\n\\nОд стандарден влез се чита процентот на примероци за поделба. Првите X% од секоја класа се земаат за тренирање, додека останатите примероци се за тестирање. \\n\\nИзградете ги моделите на класификација и одредете кој од нив има најголема точност. На стандарден излез испечатете кој е класификаторот со најголема точност. (Najgolema tocnost ima klasifikatorot Naive Bayes/Decision Tree/Random Forest/MLP)\\n\\nПотоа изградете уште еден модел за класификација со колекција на класификатори на следниот начин:\\n\\n-  Класификаторот кој има најголема точност има тежина на глас 2 (класата која ја предвидува класификаторот со најголема точност добива 2 гласа)\\n-  Сите останати класификатори имаат тежина на глас 1\\n-  За предвидена се смета класата која што ќе добие најголем број гласови\\n\\nНа пример, ако класификаторот со најголема точност и уште еден класификатор ја предвидат класата 0, а останатите два класификатори ја предвидат класата 1, тогаш класата 0 ќе има 3 гласа, а класата 1 ќе има 2 гласа. Класификаторот ја предвидува класата 0.\\nПресметајте и испечатете го одзивот на овој модел (колекцијата од класификатори).\\n\\nодзив = TP / (TP + FN)\\n\\nTP - број на точно предвидени позитивни класи\\n\\nFP - број на грешно предвидени позитивни класи\\n\\nTN - број на точно предвидени негативни класи\\n\\nFN - број на грешно предвидени негативни класи\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Дадено е податочно множество во променливата dataset. Последната колона ја претставува класата (0 или 1). Сите атрибути кои ги содржи се од нумерички тип.\n",
    "\n",
    "Потребно е да направите 4 модели на класификација:\n",
    "\n",
    "-  Наивен баесов класификатор.\n",
    "-  Дрво на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.\n",
    "-  Класификатор со колекција од 4 дрва на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.\n",
    "-  Невронска мрежа со 10 неврони, ReLU активациска функција, 0.001 рата на учење.\n",
    "\n",
    "Од стандарден влез се чита процентот на примероци за поделба. Првите X% од секоја класа се земаат за тренирање, додека останатите примероци се за тестирање. \n",
    "\n",
    "Изградете ги моделите на класификација и одредете кој од нив има најголема точност. На стандарден излез испечатете кој е класификаторот со најголема точност. (Najgolema tocnost ima klasifikatorot Naive Bayes/Decision Tree/Random Forest/MLP)\n",
    "\n",
    "Потоа изградете уште еден модел за класификација со колекција на класификатори на следниот начин:\n",
    "\n",
    "-  Класификаторот кој има најголема точност има тежина на глас 2 (класата која ја предвидува класификаторот со најголема точност добива 2 гласа)\n",
    "-  Сите останати класификатори имаат тежина на глас 1\n",
    "-  За предвидена се смета класата која што ќе добие најголем број гласови\n",
    "\n",
    "На пример, ако класификаторот со најголема точност и уште еден класификатор ја предвидат класата 0, а останатите два класификатори ја предвидат класата 1, тогаш класата 0 ќе има 3 гласа, а класата 1 ќе има 2 гласа. Класификаторот ја предвидува класата 0.\n",
    "Пресметајте и испечатете го одзивот на овој модел (колекцијата од класификатори).\n",
    "\n",
    "одзив = TP / (TP + FN)\n",
    "\n",
    "TP - број на точно предвидени позитивни класи\n",
    "\n",
    "FP - број на грешно предвидени позитивни класи\n",
    "\n",
    "TN - број на точно предвидени негативни класи\n",
    "\n",
    "FN - број на грешно предвидени негативни класи\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\n",
    "    [14.23, 1.71, 2.43, 15.6, 127, 2.8, 3.06, .28, 2.29, 5.64, 1.04, 3.92, 1065, 0],\n",
    "    [13.2, 1.78, 2.14, 11.2, 100, 2.65, 2.76, .26, 1.28, 4.38, 1.05, 3.4, 1050, 0],\n",
    "    [13.16, 2.36, 2.67, 18.6, 101, 2.8, 3.24, .3, 2.81, 5.68, 1.03, 3.17, 1185, 0],\n",
    "    [14.37, 1.95, 2.5, 16.8, 113, 3.85, 3.49, .24, 2.18, 7.8, .86, 3.45, 1480, 0],\n",
    "    [13.24, 2.59, 2.87, 21, 118, 2.8, 2.69, .39, 1.82, 4.32, 1.04, 2.93, 735, 0],\n",
    "    [14.2, 1.76, 2.45, 15.2, 112, 3.27, 3.39, .34, 1.97, 6.75, 1.05, 2.85, 1450, 0],\n",
    "    [14.39, 1.87, 2.45, 14.6, 96, 2.5, 2.52, .3, 1.98, 5.25, 1.02, 3.58, 1290, 0],\n",
    "    [14.06, 2.15, 2.61, 17.6, 121, 2.6, 2.51, .31, 1.25, 5.05, 1.06, 3.58, 1295, 0],\n",
    "    [14.83, 1.64, 2.17, 14, 97, 2.8, 2.98, .29, 1.98, 5.2, 1.08, 2.85, 1045, 0],\n",
    "    [13.86, 1.35, 2.27, 16, 98, 2.98, 3.15, .22, 1.85, 7.22, 1.01, 3.55, 1045, 0],\n",
    "    [14.1, 2.16, 2.3, 18, 105, 2.95, 3.32, .22, 2.38, 5.75, 1.25, 3.17, 1510, 0],\n",
    "    [14.12, 1.48, 2.32, 16.8, 95, 2.2, 2.43, .26, 1.57, 5, 1.17, 2.82, 1280, 0],\n",
    "    [13.75, 1.73, 2.41, 16, 89, 2.6, 2.76, .29, 1.81, 5.6, 1.15, 2.9, 1320, 0],\n",
    "    [14.75, 1.73, 2.39, 11.4, 91, 3.1, 3.69, .43, 2.81, 5.4, 1.25, 2.73, 1150, 0],\n",
    "    [14.38, 1.87, 2.38, 12, 102, 3.3, 3.64, .29, 2.96, 7.5, 1.2, 3, 1547, 0],\n",
    "    [13.63, 1.81, 2.7, 17.2, 112, 2.85, 2.91, .3, 1.46, 7.3, 1.28, 2.88, 1310, 0],\n",
    "    [14.3, 1.92, 2.72, 20, 120, 2.8, 3.14, .33, 1.97, 6.2, 1.07, 2.65, 1280, 0],\n",
    "    [13.83, 1.57, 2.62, 20, 115, 2.95, 3.4, .4, 1.72, 6.6, 1.13, 2.57, 1130, 0],\n",
    "    [14.19, 1.59, 2.48, 16.5, 108, 3.3, 3.93, .32, 1.86, 8.7, 1.23, 2.82, 1680, 0],\n",
    "    [13.64, 3.1, 2.56, 15.2, 116, 2.7, 3.03, .17, 1.66, 5.1, .96, 3.36, 845, 0],\n",
    "    [12.37, .94, 1.36, 10.6, 88, 1.98, .57, .28, .42, 1.95, 1.05, 1.82, 520, 1],\n",
    "    [12.33, 1.1, 2.28, 16, 101, 2.05, 1.09, .63, .41, 3.27, 1.25, 1.67, 680, 1],\n",
    "    [12.64, 1.36, 2.02, 16.8, 100, 2.02, 1.41, .53, .62, 5.75, .98, 1.59, 450, 1],\n",
    "    [13.67, 1.25, 1.92, 18, 94, 2.1, 1.79, .32, .73, 3.8, 1.23, 2.46, 630, 1],\n",
    "    [12.37, 1.13, 2.16, 19, 87, 3.5, 3.1, .19, 1.87, 4.45, 1.22, 2.87, 420, 1],\n",
    "    [12.17, 1.45, 2.53, 19, 104, 1.89, 1.75, .45, 1.03, 2.95, 1.45, 2.23, 355, 1],\n",
    "    [12.37, 1.21, 2.56, 18.1, 98, 2.42, 2.65, .37, 2.08, 4.6, 1.19, 2.3, 678, 1],\n",
    "    [13.11, 1.01, 1.7, 15, 78, 2.98, 3.18, .26, 2.28, 5.3, 1.12, 3.18, 502, 1],\n",
    "    [12.37, 1.17, 1.92, 19.6, 78, 2.11, 2, .27, 1.04, 4.68, 1.12, 3.48, 510, 1],\n",
    "    [13.34, .94, 2.36, 17, 110, 2.53, 1.3, .55, .42, 3.17, 1.02, 1.93, 750, 1],\n",
    "    [12.21, 1.19, 1.75, 16.8, 151, 1.85, 1.28, .14, 2.5, 2.85, 1.28, 3.07, 718, 1],\n",
    "    [12.29, 1.61, 2.21, 20.4, 103, 1.1, 1.02, .37, 1.46, 3.05, .906, 1.82, 870, 1],\n",
    "    [13.86, 1.51, 2.67, 25, 86, 2.95, 2.86, .21, 1.87, 3.38, 1.36, 3.16, 410, 1],\n",
    "    [13.49, 1.66, 2.24, 24, 87, 1.88, 1.84, .27, 1.03, 3.74, .98, 2.78, 472, 1],\n",
    "    [12.99, 1.67, 2.6, 30, 139, 3.3, 2.89, .21, 1.96, 3.35, 1.31, 3.5, 985, 1],\n",
    "    [11.96, 1.09, 2.3, 21, 101, 3.38, 2.14, .13, 1.65, 3.21, .99, 3.13, 886, 1],\n",
    "    [11.66, 1.88, 1.92, 16, 97, 1.61, 1.57, .34, 1.15, 3.8, 1.23, 2.14, 428, 1],\n",
    "    [13.03, .9, 1.71, 16, 86, 1.95, 2.03, .24, 1.46, 4.6, 1.19, 2.48, 392, 1],\n",
    "    [11.84, 2.89, 2.23, 18, 112, 1.72, 1.32, .43, .95, 2.65, .96, 2.52, 500, 1],\n",
    "    [12.33, .99, 1.95, 14.8, 136, 1.9, 1.85, .35, 2.76, 3.4, 1.06, 2.31, 750, 1],\n",
    "    [12.7, 3.87, 2.4, 23, 101, 2.83, 2.55, .43, 1.95, 2.57, 1.19, 3.13, 463, 1],\n",
    "    [12, .92, 2, 19, 86, 2.42, 2.26, .3, 1.43, 2.5, 1.38, 3.12, 278, 1],\n",
    "    [12.72, 1.81, 2.2, 18.8, 86, 2.2, 2.53, .26, 1.77, 3.9, 1.16, 3.14, 714, 1]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Solution\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_data(dataset: List[List[float]], train_size: float=0.8) -> Tuple[List, List, List, List]:\n",
    "    '''\n",
    "    Splits the dataset into training and testing data with same ratio for both classes.\n",
    "    \n",
    "    :param dataset: List of lists with float values. The last element of each list is the class label.\n",
    "    :param train_size: The percentage of the dataset that will be used for training.\n",
    "    \n",
    "    :return: Tuple containing the training and testing data for both classes.\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = [], [], [], []\n",
    "    \n",
    "    for label in [0, 1]:\n",
    "        X = [row[:-1] for row in dataset if row[-1] == label]\n",
    "        y = [label] * len(X)\n",
    "        \n",
    "        # Prvite X% se koristat za treniranje\n",
    "        X_train_, X_test_, y_train_, y_test_ = train_test_split(X, y, train_size=train_size, shuffle=False)\n",
    "        \n",
    "        # Poslednite X% se koristat za testiranje\n",
    "        # X_test_, X_train_, y_test_, y_train_ = train_test_split(\n",
    "        #     X, \n",
    "        #     y, \n",
    "        #     test_size=train_size, <- Gi zamenuvame mestata deka train_test_split prviot del go vraka kako train koga shuffle=False\n",
    "        #     shuffle=False\n",
    "        # )\n",
    "        \n",
    "        X_train.extend(X_train_) \n",
    "        X_test.extend(X_test_)\n",
    "        y_train.extend(y_train_)\n",
    "        y_test.extend(y_test_)\n",
    "        \n",
    "        # Isto raboti\n",
    "        # X_train += X_train_\n",
    "        # X_test += X_test_\n",
    "        # y_train += y_train_\n",
    "        # y_test += y_test_\n",
    "        \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset: List[List[float]]) -> None:\n",
    "    '''\n",
    "    Main function for the given task.\n",
    "    \n",
    "    :param dataset: List of lists with float values. The last element of each list is the class label.\n",
    "    '''\n",
    "    \n",
    "    train_size = int(input()) / 100.0\n",
    "    X_train, X_test, y_train, y_test = get_split_data(dataset, train_size)\n",
    "    \n",
    "    ### Model Definition\n",
    "    \n",
    "    models = [\n",
    "        GaussianNB(),\n",
    "        DecisionTreeClassifier(criterion='entropy', random_state=0),\n",
    "        RandomForestClassifier(n_estimators=4, criterion='entropy', random_state=0),\n",
    "        MLPClassifier(hidden_layer_sizes=(10,), activation='relu', learning_rate_init=0.001, random_state=0)\n",
    "    ]\n",
    "\n",
    "    ### Evaluation\n",
    "    \n",
    "    accuracies = []\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        \n",
    "    best_classifier = np.argmax(accuracies)\n",
    "    \n",
    "    map_location_to_name = {\n",
    "        0: 'Naive Bayes',\n",
    "        1: 'Decision Tree',\n",
    "        2: 'Random Forest',\n",
    "        3: 'MLP'\n",
    "    }\n",
    "    \n",
    "    print(f'Najgolema tocnost ima klasifikatorot {map_location_to_name[best_classifier]}')\n",
    "    \n",
    "    final_predictions = []\n",
    "    for x in X_test:\n",
    "        predictions = [model.predict([x])[0] for model in models]\n",
    "        prediction = np.sum(predictions) + predictions[best_classifier]\n",
    "        \n",
    "        # Ova moze deka e binarna klasifikacija pomegu 0/1\n",
    "        final_predictions.append(1 if prediction > 2 else 0)\n",
    "        \n",
    "    print(f'Odzivot na kolekcijata so klasifikatori e {recall_score(y_test, final_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Main\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najgolema tocnost ima klasifikatorot Random Forest\n",
      "Odzivot na kolekcijata so klasifikatori e 1.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
